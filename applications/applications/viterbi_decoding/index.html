<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../img/favicon.ico" />
    <title>Viterbi Decoding - HANNAH</title>
    <link rel="stylesheet" href="../../../css/theme.css" />
    <link rel="stylesheet" href="../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Viterbi Decoding";
        var mkdocs_page_input_path = "applications/applications/viterbi_decoding.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../.." class="icon icon-home"> HANNAH
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../fallacies/">Fallacies and Pitfalls</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../publications/">Publications</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../experiments/">Experiment Management</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Configuration</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../configuration/configuration/overview/">Overview</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../configuration/configuration/multi_gpu/">Multi-GPU support</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Compression</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../compression/compression/quantization/">Quantization</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../compression/compression/pruning/">Pruning</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../compression/compression/clustering/">Clustering</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../compression/compression/decomposition/">Tensor Decompositions</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../compression/compression/knowledge_distillation/">Knowledge Distillation</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Optimization</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../optimization/optimization/hyperparameter/">Hyperparameter Optimization</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Neural Architecture Search</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../neural-architecture-search/nas/legacy/">NAS (Legacy)</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../neural-architecture-search/nas/usage/">Usage</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../neural-architecture-search/nas/search_spaces/">Search Spaces</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../neural-architecture-search/nas/parametrization/">Parametrization</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../neural-architecture-search/nas/search/">Search</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../neural-architecture-search/nas/eval/">Evaluating Results</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../neural-architecture-search/nas/metrics/">Optimization Metrics</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Deployment</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../deployment/deployment/overview/">Overview</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../deployment/deployment/torchmobile/">Torch Mobile</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../deployment/deployment/trax-Ultratrail/">T-Rax Ultratrail</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../deployment/deployment/tvm/">TVM</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../deployment/deployment/tensorrt/">TensorRT</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Evaluation</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../evaluation/eval/">Evaluation</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">applications</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../seizure_detection/">Seizure Detection</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">Viterbi Decoding</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#window-size">Window size</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#visualization">Visualization</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#grid-search">Grid Search</a>
    </li>
    </ul>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Development</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../development/devel/overview/">Overview</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../development/devel/debugging/">Debugging</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../development/devel/profiling/">Profiling</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../development/devel/api/">API Documentation</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../..">HANNAH</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">applications</li>
      <li class="breadcrumb-item active">Viterbi Decoding</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="post-processing-with-viterbi-decoding">Post-Processing with Viterbi Decoding</h1>
<p>This implementation for the Post-Processing of CNN evaluations with a Hidden Markov Model (HMM) and Viterbi decoding in HANNAH is based on <cite><strong>Precise Localization within the GI Tract</strong> [1]</cite> and <cite><strong>Energy-efficient Seizure Detection</strong> [2]</cite>. The datasets used in those two publications, Video Capsule Endoscopy (VCE) datasets (Rhode Island and Galar) and EEG datasets (CHB-MIT), are supported. However, in general, the main criteria is that the test set is ordered in time and thus, this can be applied to many other applications and datasets as well. For the Rhode Island, the Galar and the CHB-MIT dataset, the ordering is ensured within the dataset files in HANNAH. Additionally, we combined the usage of neural networks with a HMM. After a network is trained on the given datasets, the evaluations of the CNN can be used as a direct input as observations for a HMM and subsequent Viterbi Decoding.</p>
<p>Next, the Viterbi Decoding computes the most likely sequence of hidden states (or classes in this case) based on the provided observations given by the neural network. For applications such as the VCE, a HMM in combination with Viterbi Decoding is a very reasonable choice as there is some preknowledge about this application. For example, we can leverage the knowledge in which order the capsule traverses the gastrointestinal tract. Furthermore, we know that the capsule cannot move back to a preceding organ after it has entered the next one. This can be encoded in the transition probabilities of the HMM.</p>
<p>As a first step, one needs to invoke a training with HANNAH for one of the supported datasets. This generates two output files named as <code>{model_name}_cnn_train_output</code> and <code>{model_name}_cnn_train_output</code>. Both are CSV Files, containing for each input one row, where the columns indicate the study id, the CNN evaluation and the true label (e.g. <code>100,0,1</code> for study ID=100, prediction of CNN = 0, true label = 1). Subsequently, they can be read into <code>hmm_window.py</code> (which allows to compute the Viterbi algorithm with a predefined window size).</p>
<p>Thus, the Viterbi Decoding can be invoked by:</p>
<div class="codehilite"><pre><span></span><code>python hannah/sequential_analysis/hmm/hmm_window.py --cnn_output_dir &#39;/PATH/TO/TRAINED_MODELS/DIR/&#39; --class_of_interest 2
</code></pre></div>

<p>Parameters that can be specified are:</p>
<dl>
<dt><code>cnn_output_dir</code></dt>
<dd>type = str, Path to the output of the trained CNN.</dd>
<dt><code>model_name</code></dt>
<dd>default = "mobilenetv3_small_075", Name of the CNN used for training.</dd>
<dt><code>window_size</code></dt>
<dd>default = 300, Window size used during Viterbi Decoding.</dd>
<dt><code>window_size_sweep</code></dt>
<dd>default = False, type=bool, Whether to perform a window size sweep first.</dd>
<dt><code>class_of_interest</code></dt>
<dd>type = int, must be provided - the class number for which the delay should be tracked, e.g. 1 for seizure detection, 2 for small intestine in RI dataset, 3 for small intestine in Galar dataset.</dd>
</dl>
<p>This reads the CSV files into Pandas Dataframes with the following columns <code>["id", "preds", "labels"]</code> for both the train and the test set.
The CNN output evaluated on the train set is used to compute the confusion matrix for the train set. This naturally encodes the emission probabilities. Thus, this is used to generate the emission matrix for the HMM. </p>
<h2 id="window-size">Window size</h2>
<p>The precise value of this parameter is not too crucial for the discussed settings. However, if one considers the final hardware architecture, this should be kept in mind. With the given files, a window size search can be performed, if the window_size_sweep parameter is set to True. It performs a simple grid search by running the Viterbi decoding with the same samples for different window sizes. The window sizes are currently encoded in <code>window_size_sweep.py</code> and can be adjusted. The file outputs two additional plots <code>boxplot_window_sweep.pdf</code> and <code>window_size_sweep.pdf</code>. </p>
<h2 id="visualization">Visualization</h2>
<p>For all test studies, one final confusion matrix is generated as well as a plot with the total error percentages. Furthermore, for a single study (default is the first one of the test set), the predictions for the CNN only, the true labels and the Viterbi predictions are plotted. This serves as a comparison to visualize the flaws and strengths of both methods (or their combination).
All figures are saved to <code>hannah/hannah/sequential_analysis/hmm/figures_hmm</code>.</p>
<h2 id="grid-search">Grid Search</h2>
<p>A simple grid search can be performed to search for the best transition probabilities (the emission probabalities are directly encoded in the confusion matrix of the CNN evaluated on the train set) by running:</p>
<div class="codehilite"><pre><span></span><code>python hannah/sequential_analysis/hmm/grid_search_trans.py --cnn_output_dir &#39;/PATH/TO/TRAINED_MODELS/DIR/&#39;
</code></pre></div>

<p>Parameters that can be specified are:</p>
<dl>
<dt><code>cnn_output_dir</code></dt>
<dd>type = str, Path to the output of the trained CNN.</dd>
<dt><code>model_name</code></dt>
<dd>default = "mobilenetv3_small_075", type=str, Name of the CNN used for training.</dd>
<dt><code>values</code></dt>
<dd>default = [0.9, 0.95, 0.99, 0.999], type=list of floats, A list of possible non-logarithmic values to choose from during the grid search. A Permutation of all combinations is performed</dd>
</dl>
<p>For each combination of transition probabilities, the Viterbi Decoding is performed and the resulting accuracies plotted (<code>acc_grid_search.pdf</code>).</p>
<p><strong>Note:</strong> A setting such as given in VCE studies is assumed here (from one state only transitioning to the succeeding state is possible <strong>and</strong> once the last state is reached, there is no possibility to transfer to another state.)</p>
<h1 id="examples">Examples</h1>
<p>Below, for three patients exemplarily (one of each of the integrated datasets) the predictions of the CNN only vs the combinatorial approach of CNN and HMM/Viterbi decoding are visualized.</p>
<h3 id="galar-and-rhode-island-dataset-vce-images-as-input">Galar and Rhode Island dataset (VCE - images as input)</h3>
<p><img src="/../assets/VCE_single_patient_Gal.png" alt="Single patient of Galar dataset" width="500"/>    <img src="/../assets/VCE_single_patient_RI.png" alt="Single patient of Rhode Island dataset" width="500"/></p>
<h3 id="chbmit-dataset-eeg-data-as-input">CHBMIT dataset (EEG data as input)</h3>
<p><img src="/../assets/CHBMIT_single_patient_HMM.png" alt="Single patient of EEG dataset" width="500"/></p>
<h1 id="references">References</h1>
<p>[1] Werner, J., Gerum, C., Reiber, M., Nick, J., &amp; Bringmann, O. (2023, October). Precise localization within the GI tract by combining classification of CNNs and time-series analysis of HMMs. In International Workshop on Machine Learning in Medical Imaging (pp. 174-183). Cham: Springer Nature Switzerland.</p>
<p>[2] Werner, J., Kohli, B., Bernardo, P. P., Gerum, C., &amp; Bringmann, O. (2024, June). Energy-Efficient Seizure Detection Suitable for Low-Power Applications. In 2024 International Joint Conference on Neural Networks (IJCNN) (pp. 1-8). IEEE.</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../seizure_detection/" class="btn btn-neutral float-left" title="Seizure Detection"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../../../development/devel/overview/" class="btn btn-neutral float-right" title="Overview">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../seizure_detection/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../../../development/devel/overview/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../..";</script>
    <script src="../../../js/theme_extra.js"></script>
    <script src="../../../js/theme.js"></script>
      <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
